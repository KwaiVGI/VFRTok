# model
image_size: 256
num_frames: 1
model: AE-16
enc_type: vit
dec_type: vit
codebook_embed_dim: 32
num_latent_tokens: 128
base_image_size: 256
encoder_model: vit_base_patch14_dinov2.lvd142m
decoder_model: vit_base_patch14_dinov2.lvd142m
encoder_tuning_method: full
decoder_tuning_method: full
encoder_pretrained: false
decoder_pretrained: false
encoder_patch_size: 8
decoder_patch_size: 8
t_patch_size: 1
dec_seperate_mask_token: false
rope_mixed: false
rope_theta: 10000.0
rope_theta_t: 10000.0
to_pixel: linear
use_ape: false
use_rope: true

# loss
reconstruction_weight: 1.0
reconstruction_loss: l1
perceptual_weight: 1.0
perceptual_loss: vgg
perceptual_model: vgg
perceptual_dino_variants: depth12_no_train
perceptual_intermediate_loss: false
perceptual_logit_loss: false
perceptual_resize: false
perceptual_warmup: 10000
disc_weight: 0.2
disc_start: 30000
disc_dim: 64
disc_type: dino
disc_loss: hinge
gen_loss: hinge
lecam_loss_weight: 0.001
use_diff_aug: true
disc_cr_loss_weight: 4.0
disc_adaptive_weight: true
dropout_p: 0.0

# data
dataset: imagenet
data_column: image_path
data_path: data/imagenet.csv
val_data_path: data/imagenet_val.csv

# train
max_train_steps: 500000
epochs: 100
global_seed: 42
num_workers: 16
log_every: 50
val_every: 5000
ckpt_every: 5000